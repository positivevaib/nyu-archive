Vaibhav A Gadodia
Basic Algorithms - HW 2


Problem 3

Algorithm CALLING-FUNCTION(heap H, valueType x, int k)										
1. global count <- 0											
2. boolean1, boolean2 <- false									
3. if H.root.value < x											
4. 	count++												
5.	if H.root.child1 != null and H.root.child1.value < x						
6.		boolean1 <- RECURSIVE-FUNCTION(H.root.child1, ++count, x, k)				
7.	if H.root.child2 != null and H.root.child2.value < x						
8.		boolean2 <- RECURSIVE-FUNCTION(H.root.child2, ++count, x, k)				
9. return boolean1 or boolean2 or count >= k								

Algorithm RECURSIVE-FUNCTION(node N, int count, valueType x, int k)						
1. if count >= k											
2. 	return true											
3. boolean1, boolean2 <- false										
4. if N.child1 != null and N.child1.value < x								
5. 	boolean1 <- RECURSIVE-FUNCTION(N.child1, ++count, x, k)						
6. if N.child2 != null and N.child2.value < x								
7. 	boolean2 <- RECURSIVE-FUNCTION(N.child2, ++count, x, k)						
8. return boolean1 or boolean2									

Total cost of CALLING-FUNCTION = O(k)

RECURSIVE-FUNCTION will either never be called or be called (k-1) times in total. This is so because this function is only used to visit the first (k-1) nodes (not including the root) that have values less than x and the function is able to terminate once it visits the k-th node because of the global count variable that keeps track of all valid nodes that have been visited.


Problem 4

Algorithm K-WAY-MERGE(int n, list L1, list L2, ... , list LK)					
1. H <- new heap											
2. sorted <- new list											
3. for all lists										
4. 	H.insert(list.min)										
5. 	list.deleteMin()									
6. for i = 1 to n										
7. 	if i != n											
8. 		sorted.insert(H.min)							
9. 		originalListRef <- H.min.orignialList						
10. 		H.deleteMin()	
11.		if originalListRef.size != 0										
12. 			H.insert(originalListRef.min)								
13. 			originalListRef.deleteMin()								
14. 	else												
15. 		sorted.insert(H.min)									
16. return sorted											

Total cost of K-WAY-MERGE = O(nlog(k))

The cost to build the heap H is O(log(k)) as it will have k elements (the minimum element from each original list). Also, the cost to delete and then replace the deleted minimum element from heap H is O(log(k)) and since, the deletion and insertion is performed n times, the total replacement cost is O(nlog(k)). Thus, the total cost is O(n(log(k))

This is accomplished by designing the algorithm so that each entry in heap H doesn't just have its own value but also the reference to the list that it originally belonged to. This allows the algorithm to not have to test the minimum elements of all k lists against each other to find the smallest among them.

The memory used in this algorithm is O(k) as heap H that is maintained to sort the lists only ever has k elements at a time.


Problem 5

Data Structure:

- The data structure to use here is a 2-3 tree where the values are stored at the leaf nodes in the order that they are inserted in the tree. For instance, if values 1, 7, 5 ..., 4 are inserted in that order, then the left-most leaf will have value 1, the next leaf, value 7 and so on, with the right most leaf having value 4. Here, the values can be repeated as the values themselves don't matter, rather it is the insertion order that matters. 

- The internal nodes in this tree will have the total number of leaf nodes in the subtree rooted at them. For instance, in an internal node that is the root of a subtree with 5 leaf nodes, the internal node will have value 5.

class InternalNode {
	int totalLeafNodes
}

Algorithms:

i) To create a new list with one item is as simple as instantiating a new 2-3 tree and inserting that value in it, which takes constant time as it only involves the creation of a leaf node.

ii) To concatenate two lists in time O(log(n)), the algorithm to be used is the same as the join operation for ordinary 2-3 trees. This is so because much like the join operation that relied on the assumption of the two trees (ones being merged) being in the correct final order, the list concatenation doesn't need to re-order any leaf nodes in the final tree.

iii) To split the list into two with one containing the first k items and the other, the rest, the algorithm to be used is very similar to the split operation for ordinary 2-3 trees. 

- Much like the ordinary split operation, this algorithm would also involve traversing down to the k-th leaf node and deleting the path travelled, thereafter, merging the free standing trees from inside out. 

- The difference here is in the search procedure to find the k-th node. The node would be found by levering the information about the number of leaf nodes in the internal nodes. The search algorithm would keep track of a global count variable (which would remember the number of leaf nodes in the left subtree not visited) and would only visit that child node whose descendent leaf nodes will be in the range that contains the k-th leaf. For instance, while traversing down the path, if the search algorithm is at an internal node - and it needs to find the 7th leaf node - and the count variable is 4, that would indicate that the search algorithm would have to travel down to the leftmost child node where (count + child.totLeaves) > k

- This algorithm would have the same running time as the ordinary split operation because the only difference here is in the search operation but even there, the total operational calls are the same. Therefore, the algorithm would run in O(log(n)) time.

iv) Here, the algorithm would be similar to the search algorithm except that it would not return a boolean but rather the value of the k-th leaf. Also, the algorithm would not compare the child node values as it would have in the ordinary case. Instead, it would use a global count variable - mentioned above in part iii - and would compare the sum of count and child node's descendant leafs to figure out its path. Therefore, the running time would be O(log(n)) much like the ordinary search operation.


Problem 6

To reverse a list in constant time, the tree's internal nodes would have to contain a reverse bit in addition to the number of leaf nodes in their subtree. If this reverse bit were to be 1, then the subtree rooted at that node would be treated as the logical reverse of the list that it would otherwise represent. This would run in constant time because to reverse a list, all that would need to be done would be to change the reverse bit of the root to 1.

class InternalNode {
	int totalLeafNodes
	int reverseBit
}

The other operations discussed in Problem 5 can still be implemented in their usual time bounds with this approach, as shown below.

i) Creating a new list with one item would still run in constant time as it would only involve the instantiation of a leaf node.

ii) Concatenation of two lists would still run in O(log(n)) time with a few changes to the algorithm that was described in the previous problem. 

- In the case where heights of the two trees being merged are equal, the algorithm would work as usual. 

- However, in cases where the heights are different, the algorithm would first have to traverse its way down to the node where the tree with the smaller height would be merged as a child. And on the path to that node, the algorithm would have to shovel the reverse bits down, whenever it visits a node with its reverse bit set to 1. On such instances, when the reverse bit turns out to be 1, the algorithm would have to reverse the order of that node's children such that the rightmost child becomes the left most and vice versa. Also, after this change of order, the reverse bit of the node would have to be set to 0 while the reverse bits of the children would themselves be reversed. So, a child with reverse bit 1 would now have its reverse bit set to 0 and vice versa. 

- Once this sub-routine has shoveled the reverse bits on its path to the node where the new tree is to be inserted, the ordinary merge operation would take over. This new procedure would run in O(log(n)) time because much like the ordinary merge operation, the search (and shovel) operation also has a runtime of O(log(n)).

iii) Splitting the list into two given a position k would run in its usual O(log(n)) time with a few modifications to the algorithm described previously. 

- The only difference from the split and merge operations of the previous problem would be that while traversing down the path, before deleting the nodes along that path, the reverse bit of those nodes would be shoveled down as described in the concatenation part above. The rest of the procedure involving the merger of free standing trees would proceed as usual.

iv) Reporting the k-th item in the tree would run in O(log(n)) time because as the search algorithm traverses its way down the tree, it would shovel the reverse bits and rearrange the child nodes as described in the previous parts. This way the algorithm wouldn't pick out the wrong item as the k-th entry and the runtime would remain the same.